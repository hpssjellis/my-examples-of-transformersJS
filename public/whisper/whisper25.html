<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Whisper-base Live Transcription</title>
  <script type="module">
    import { pipeline } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.2.2';

    window.loadModel = loadModel;
    window.startRecording = startRecording;
    window.stopRecording = stopRecording;

    let myASR;
    let myAudioContext;
    let myWorkletNode;
    let myAudioBuffer = [];
    const mySampleRate = 16000;
    const myChunkDuration = 2; // seconds

    async function loadModel() {
      await loadAndAddAudioWorkletModuleFromURL(); // Load the script first
      myASR = await pipeline("automatic-speech-recognition", "Xenova/whisper-tiny");
      document.getElementById('loadModelButton').disabled = true;
      document.getElementById('startButton').disabled = false;
      console.log("Model loaded.");
    }

    async function startRecording() {
      document.getElementById('transcription').innerText = "";
      document.getElementById('startButton').disabled = true;
      document.getElementById('stopButton').disabled = false;
      const myLanguage = document.getElementById('myLanguageSelect').value;
      myAudioContext = new AudioContext({ sampleRate: mySampleRate });

      myWorkletNode = new AudioWorkletNode(myAudioContext, 'my-audio-processor');
      myWorkletNode.port.onmessage = async (event) => {
        myAudioBuffer.push(...event.data);
        if (myAudioBuffer.length >= mySampleRate * myChunkDuration) {
          let myChunk = myAudioBuffer.slice(0, mySampleRate * myChunkDuration);
          myAudioBuffer = myAudioBuffer.slice(mySampleRate * myChunkDuration);

          const myResult = await myASR(new Float32Array(myChunk), { language: myLanguage });
          let myText = myResult.text.trim();
          console.log(myText)
          if (!['[BLANK_AUDIO]', '[MUSIC]', '[BEEP]', '[COUGH]', '[INAUDIBLE]'].includes(myText)) {
            document.getElementById('transcription').innerText += myResult.text;
            if (myResult.text.includes('[BLANK_AUDIO]')) { document.getElementById('transcription').innerText += '\n' }
          }
        }
      };

      const myStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mySource = myAudioContext.createMediaStreamSource(myStream);
      mySource.connect(myWorkletNode);

      console.log("Live transcription started...");
    }

    function stopRecording() {
      document.getElementById('startButton').disabled = false;
      document.getElementById('stopButton').disabled = true;
      myWorkletNode.disconnect();
      myAudioContext.close();
      console.log("Recording stopped.");
    }

    async function loadAndAddAudioWorkletModuleFromURL() {
      const scriptURL = 'https://your-audioworklet-script-url.js'; // Replace with the actual URL of your AudioWorklet script
      await myAudioContext.audioWorklet.addModule(scriptURL);
      console.log("AudioWorklet script added successfully.");
    }

    window.loadAndAddAudioWorkletModuleFromURL = loadAndAddAudioWorkletModuleFromURL;
  </script>
</head>
<body>
  <h1>Live Whisper-base Transcription</h1>
  <input type="button" id="loadModelButton" value="Load Model" onclick="loadModel()">
  <input type="button" id="startButton" value="Start Live Transcription" onclick="startRecording()" disabled>
  <input type="button" id="stopButton" value="Stop" onclick="stopRecording()" disabled><br>
  
  <select id="myLanguageSelect">
    <option value="ar">Arabic</option>
    <option value="zh">Chinese</option>
    <option value="en" selected>English</option>
    <option value="fr">French</option>
    <option value="de">German</option>
    <option value="it">Italian</option>
    <option value="ja">Japanese</option>
    <option value="ru">Russian</option>
    <option value="es">Spanish</option>
  </select>

  <h2>Transcription:</h2>
  <p id="transcription">...</p>

  Use at your own risk, by <a href="https://www.linkedin.com/in/jeremy-ellis-4237a9bb/">Jeremy Ellis LinkedIn</a><br>
  Github index at <a href="https://hpssjellis.github.io/my-examples-of-ai-agents/public/index.html">hpssjellis.github.io/my-examples-of-ai-agents/public/index.html</a><br>
  My transformersjs github where the work was done <a href="https://github.com/hpssjellis/my-examples-of-transformersJS">https://github.com/hpssjellis/my-examples-of-transformersJS</a><br>
  My Github <a href="https://github.com/hpssjellis">Profile</a><br>
</body>
</html>
