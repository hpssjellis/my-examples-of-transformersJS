number,content,source
1,"Machine Learning SystemsPrinciples and Practices of Engineering Artificially Intelligent SystemsAuthor, Editor & CuratorAffiliationVijay Janapa Reddi Harvard UniversityLast UpdatedMay 14, 2025AbstractMachine Learning Systems presents a comprehensive approach to understanding and engineering machine learning (ML). While many resources focus on ML algorithms and model architectures, this book serves as a bridge between theoretical foundations and practical engineering.","preface (part 1)"
10,"sform lives every day. Your selfless contributions remind me to persevere.Last but certainly not least, this work would not be possible without the unwavering support of my wonderful wife and children. Their love, patience, and encouragement form the foundation that enables me to pursue my passion and bring this work to life. For this, and so much more, I am deeply grateful.— Prof. Vijay Janapa Reddi","Author’s Note (part 9)"
100,"and practical developments in implementation methodologies. This development mirrors the evolution of other scientific and engineering disciplines—from mechanical engineering’s advancement from basic force principles to contemporary robotics, to electrical engineering’s progression from fundamental electromagnetic theory to modern power and communication networks. Analysis of this historical trajectory reveals both the technological innovations leading to current machine learning approaches and","1.2 AI and ML Basics (part 7)"
101,"the emergence of deep reinforcement learning that inform contemporary AI system development.","1.2 AI and ML Basics (part 8)"
102,"The evolution of AI, depicted in the timeline shown in Figure 1.1, highlights key milestones such as the development of the perceptron in 1957 by Frank Rosenblatt, a foundational element for modern neural networks. Imagine walking into a computer lab in 1965. You’d find room-sized mainframes running programs that could prove basic mathematical theorems or play simple games like tic-tac-toe. These early artificial intelligence systems, while groundbreaking for their time, were a far cry from toda","1.3 AI Evolution (part 1)"
103,"y’s machine learning systems that can detect cancer in medical images or understand human speech. The timeline shows the progression from early innovations like the ELIZA chatbot in 1966, to significant breakthroughs such as IBM’s Deep Blue defeating chess champion Garry Kasparov in 1997. More recent advancements include the introduction of OpenAI’s GPT-3 in 2020 and GPT-4 in 2023, demonstrating the dramatic evolution and increasing complexity of AI systems over the decades.Figure 1.","1.3 AI Evolution (part 2)"
104,"1: Milestones in AI from 1950 to 2020. Source: IEEE SpectrumLet’s explore how we got here.","1.3 AI Evolution (part 3)"
105,"The story of machine learning begins at the historic Dartmouth Conference in 1956, where pioneers like John McCarthy, Marvin Minsky, and Claude Shannon first coined the term “artificial intelligence.” Their approach was based on a compelling idea: intelligence could be reduced to symbol manipulation. Consider Daniel Bobrow’s STUDENT system from 1964, one of the first AI programs that could solve algebra word problems.","1.3.1 Symbolic AI Era (part 1)"
106,"It was one of the first AI programs to demonstrate natural language understanding by converting English text into algebraic equations, marking an important milestone in symbolic AI.Example: STUDENT (1964)Problem: ""If the number of customers Tom gets is twice thesquare of 20% of the number of advertisements he runs, andthe number of advertisements is 45, what is the number ofcustomers Tom gets?""STUDENT would:1. Parse the English text2. Convert it to algebraic equations3.","1.3.1 Symbolic AI Era (part 2)"
107,"Solve the equation: n = 2(0.2 × 45)²4. Provide the answer: 162 customersEarly AI like STUDENT suffered from a fundamental limitation: they could only handle inputs that exactly matched their pre-programmed patterns and rules. Imagine a language translator that only works when sentences follow perfect grammatical structure—even slight variations like changing word order, using synonyms, or natural speech patterns would cause the STUDENT to fail.","1.3.1 Symbolic AI Era (part 3)"
108,"This “brittleness” meant that while these solutions could appear intelligent when handling very specific cases they were designed for, they would break down completely when faced with even minor variations or real-world complexity. This limitation wasn’t just a technical inconvenience—it revealed a deeper problem with rule-based approaches to AI: they couldn’t genuinely understand or generalize from their programming, they could only match and manipulate patterns exactly as specified.","1.3.1 Symbolic AI Era (part 4)"
109,"By the mid-1970s, researchers realized that general AI was too ambitious. Instead, they focused on capturing human expert knowledge in specific domains. MYCIN, developed at Stanford, was one of the first large-scale expert systems designed to diagnose blood infections.Example: MYCIN (1976)Rule Example from MYCIN:IF  The infection is primary-bacteremia  The site of the culture is one of the sterile sites  The suspected portal of entry is the gastrointestinal tractTHEN  Found suggestive e","1.3.2 Expert Systems Era (part 1)"
11,"About the BookOverviewPurpose of the BookWelcome to this collaborative textbook. It originated as part of the CS249r: Tiny Machine Learning course that Prof. Vijay Janapa Reddi teaches at Harvard University.The goal of this book is to provide a resource for educators and learners seeking to understand the principles and practices of machine learning systems. This book is continually updated to incorporate the latest insights and effective teaching strategies with the intent that it remains","About the Book (part 1)"
110,"vidence (0.7) that infection is bacteroidWhile MYCIN represented a major advance in medical AI with its 600 expert rules for diagnosing blood infections, it revealed fundamental challenges that still plague ML today. Getting domain knowledge from human experts and converting it into precise rules proved incredibly time-consuming and difficult—doctors often couldn’t explain exactly how they made decisions.","1.3.2 Expert Systems Era (part 2)"
111,"MYCIN struggled with uncertain or incomplete information, unlike human doctors who could make educated guesses. Perhaps most importantly, maintaining and updating the rule base became exponentially more complex as MYCIN grew—adding new rules often conflicted with existing ones, and medical knowledge itself kept evolving. These same challenges of knowledge capture, uncertainty handling, and maintenance remain central concerns in modern machine learning, even though we now use different technical","1.3.2 Expert Systems Era (part 3)"
112,"approaches to address them.","1.3.2 Expert Systems Era (part 4)"
113,"The 1990s marked a radical transformation in artificial intelligence as the field moved away from hand-coded rules toward statistical learning approaches. This wasn’t a simple choice—it was driven by three converging factors that made statistical methods both possible and powerful. The digital revolution meant massive amounts of data were suddenly available to train the algorithms. Moore’s Law delivered the computational power needed to process this data effectively.","1.3.3 Statistical Learning Era (part 1)"
114,"And researchers developed new algorithms like Support Vector Machines and improved neural networks that could actually learn patterns from this data rather than following pre-programmed rules. This combination fundamentally changed how we built AI: instead of trying to encode human knowledge directly, we could now let machines discover patterns automatically from examples, leading to more robust and adaptable AI.","1.3.3 Statistical Learning Era (part 2)"
115,"Consider how email spam filtering evolved:Example: Early Spam Detection SystemsRule-based (1980s):IF contains(""viagra"") OR contains(""winner"") THEN spamStatistical (1990s):P(spam|word) = (frequency in spam emails) / (total frequency)Combined using Naive Bayes:P(spam|email) ∝ P(spam) × ∏ P(word|spam)The move to statistical approaches fundamentally changed how we think about building AI by introducing three core concepts that remain important today.","1.3.3 Statistical Learning Era (part 3)"
116,"First, the quality and quantity of training data became as important as the algorithms themselves—AI could only learn patterns that were present in its training examples. Second, we needed rigorous ways to evaluate how well AI actually performed, leading to metrics that could measure success and compare different approaches. Third, we discovered an inherent tension between precision (being right when we make a prediction) and recall (catching all the cases we should find), forcing designers to","1.3.3 Statistical Learning Era (part 4)"
117,"make explicit trade-offs based on their application’s needs. For example, a spam filter might tolerate some spam to avoid blocking important emails, while medical diagnosis might need to catch every potential case even if it means more false alarms.Table 1.1 encapsulates the evolutionary journey of AI approaches we have discussed so far, highlighting the key strengths and capabilities that emerged with each new paradigm.","1.3.3 Statistical Learning Era (part 5)"
118,"As we move from left to right across the table, we can observe several important trends. We will talk about shallow and deep learning next, but it is useful to understand the trade-offs between the approaches we have covered so far.Table 1.1: Evolution of AI—Key Positive AspectsAspectSymbolic AIExpert SystemsStatistical LearningShallow / Deep LearningKey StrengthLogical reasoningDomain expertiseVersatilityPattern recognitionBest Use CaseWell-defined, rule-based problemsSpecific d","1.3.3 Statistical Learning Era (part 6)"
119,"omain problemsVarious structured data problemsComplex, unstructured data problemsData HandlingMinimal data neededDomain knowledge-basedModerate data requiredLarge-scale data processingAdaptabilityFixed rulesDomain-specific adaptabilityAdaptable to various domainsHighly adaptable to diverse tasksProblem ComplexitySimple, logic-basedComplicated, domain- specificComplex, structuredHighly complex, unstructuredThe table serves as a bridge between the early approaches we’ve discussed","1.3.3 Statistical Learning Era (part 7)"
12,"It emphasizes the systems context that engineers need to master when building AI solutions in the real world. The text progresses from foundational concepts to advanced system design, integrating topics such as data engineering, model optimization, hardware-aware training approaches, and inference acceleration strategies. Throughout the book, readers develop a principled understanding of ML systems engineering, learning to reason about system architectures and address critical challenges in are","preface (part 2)"
120,"and the more recent developments in shallow and deep learning that we’ll explore next. It sets the stage for understanding why certain approaches gained prominence in different eras and how each new paradigm built upon and addressed the limitations of its predecessors. Moreover, it illustrates how the strengths of earlier approaches continue to influence and enhance modern AI techniques, particularly in the era of foundation models.","1.3.3 Statistical Learning Era (part 8)"
121,"The 2000s marked a fascinating period in machine learning history that we now call the ``shallow learning’’ era. To understand why it’s “shallow,” imagine building a house: deep learning (which came later) is like having multiple construction crews working at different levels simultaneously, each crew learning from the work of crews below them. In contrast, shallow learning typically had just one or two levels of processing—like having just a foundation crew and a framing crew.","1.3.4 Shallow Learning Era (part 1)"
122,"During this time, several powerful algorithms dominated the machine learning landscape. Each brought unique strengths to different problems: Decision trees provided interpretable results by making choices much like a flowchart. K-nearest neighbors made predictions by finding similar examples in past data, like asking your most experienced neighbors for advice. Linear and logistic regression offered straightforward, interpretable models that worked well for many real-world problems.","1.3.4 Shallow Learning Era (part 2)"
123,"Support Vector Machines (SVMs) excelled at finding complex boundaries between categories using the “kernel trick”—imagine being able to untangle a bowl of spaghetti into straight lines by lifting it into a higher dimension. These algorithms formed the foundation of practical machine learning.Consider a typical computer vision solution from 2005:Example: Traditional Computer Vision Pipeline1. Manual Feature Extraction  - SIFT (Scale-Invariant Feature Transform)  - HOG (Histogram of Orient","1.3.4 Shallow Learning Era (part 3)"
124,"ed Gradients)  - Gabor filters2. Feature Selection/Engineering3. ""Shallow"" Learning Model (e.g., SVM)4. Post-processingWhat made this era distinct was its hybrid approach: human-engineered features combined with statistical learning. They had strong mathematical foundations (researchers could prove why they worked). They performed well even with limited data. They were computationally efficient. They produced reliable, reproducible results.","1.3.4 Shallow Learning Era (part 4)"
125,"Take the example of face detection, where the Viola-Jones algorithm (2001) achieved real-time performance using simple rectangular features and a cascade of classifiers. This algorithm powered digital camera face detection for nearly a decade.","1.3.4 Shallow Learning Era (part 5)"
126,"While Support Vector Machines excelled at finding complex boundaries between categories using mathematical transformations, deep learning took a radically different approach inspired by the human brain’s architecture. Deep learning is built from layers of artificial neurons, where each layer learns to transform its input data into increasingly abstract representations. Imagine processing an image of a cat: the first layer might learn to detect simple edges and contrasts, the next layer combines","1.3.5 Deep Learning Era (part 1)"
127,"these into basic shapes and textures, another layer might recognize whiskers and pointy ears, and the final layers assemble these features into the concept of “cat.”Unlike shallow learning methods that required humans to carefully engineer features, deep learning networks can automatically discover useful features directly from raw data. This ability to learn hierarchical representations—from simple to complex, concrete to abstract—is what makes deep learning “deep,” and it turned out to be a","1.3.5 Deep Learning Era (part 2)"
128,"remarkably powerful approach for handling complex, real-world data like images, speech, and text.In 2012, a deep neural network called AlexNet, shown in Figure 1.2, achieved a breakthrough in the ImageNet competition that would transform the field of machine learning. The challenge was formidable: correctly classify 1.2 million high-resolution images into 1,000 different categories. While previous approaches struggled with error rates above 25%, AlexNet achieved a 15.","1.3.5 Deep Learning Era (part 3)"
129,"3% error rate, dramatically outperforming all existing methods.The success of AlexNet wasn’t just a technical achievement—it was a watershed moment that demonstrated the practical viability of deep learning. It showed that with sufficient data, computational power, and architectural innovations, neural networks could outperform hand-engineered features and shallow learning methods that had dominated the field for decades.","1.3.5 Deep Learning Era (part 4)"
13,"a valuable resource in this fast-evolving field. So please check back often!Context and DevelopmentThe book originated as a collaborative effort with contributions from students, researchers, and practitioners. While maintaining its academic rigor and real-world applicability, it continues to evolve through regular updates and careful curation to reflect the latest developments in machine learning systems.","About the Book (part 2)"
130,"This single result triggered an explosion of research and applications in deep learning that continues to this day.Figure 1.2: Deep neural network architecture for Alexnet. Source: Krizhevsky, Sutskever, and Hinton (2017)Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. 2017. “ImageNet Classification with Deep Convolutional Neural Networks.” Communications of the ACM 60 (6): 84–90. https://doi.org/10.1145/3065386.","1.3.5 Deep Learning Era (part 5)"
131,"From this foundation, deep learning entered an era of unprecedented scale. By the late 2010s, companies like Google, Facebook, and OpenAI were training neural networks thousands of times larger than AlexNet. These massive models, often called “foundation models,” took deep learning to new heights. GPT-3, released in 2020, contained 175 billion parameters—imagine a student that could read through all of Wikipedia multiple times and learn patterns from every article.","1.3.5 Deep Learning Era (part 6)"
132,"These models showed remarkable abilities: writing human-like text, engaging in conversation, generating images from descriptions, and even writing computer code. The key insight was simple but powerful: as we made neural networks bigger and fed them more data, they became capable of solving increasingly complex tasks. However, this scale brought unprecedented systems challenges: how do you efficiently train models that require thousands of GPUs working in parallel?","1.3.5 Deep Learning Era (part 7)"
133,"How do you store and serve models that are hundreds of gigabytes in size? How do you handle the massive datasets needed for training?The deep learning revolution of 2012 didn’t emerge from nowhere—it was built on neural network research dating back to the 1950s. The story begins with Frank Rosenblatt’s Perceptron in 1957, which captured the imagination of researchers by showing how a simple artificial neuron could learn to classify patterns.","1.3.5 Deep Learning Era (part 8)"
134,"While it could only handle linearly separable problems—a limitation dramatically highlighted by Minsky and Papert’s 1969 book “Perceptrons”—it introduced the fundamental concept of trainable neural networks. The 1980s brought more important breakthroughs: Rumelhart, Hinton, and Williams introduced backpropagation in 1986, providing a systematic way to train multi-layer networks, while Yann LeCun demonstrated its practical application in recognizing handwritten digits using convolutional neural","1.3.5 Deep Learning Era (part 9)"
135,"networks (CNNs).Important 1.1: Convolutional Network Demo from 1989Yet these networks largely languished through the 1990s and 2000s, not because the ideas were wrong, but because they were ahead of their time—the field lacked three important ingredients: sufficient data to train complex networks, enough computational power to process this data, and the technical innovations needed to train very deep networks effectively.","1.3.5 Deep Learning Era (part 10)"
136,"The field had to wait for the convergence of big data, better computing hardware, and algorithmic breakthroughs before deep learning’s potential could be unlocked. This long gestation period helps explain why the 2012 ImageNet moment was less a sudden revolution and more the culmination of decades of accumulated research finally finding its moment. As we’ll explore in the following sections, this evolution has led to two significant developments in the field.","1.3.5 Deep Learning Era (part 11)"
137,"First, it has given rise to define the field of machine learning systems engineering, a discipline that teaches how to bridge the gap between theoretical advancements and practical implementation. Second, it has necessitated a more comprehensive definition of machine learning systems, one that encompasses not just algorithms, but also data and computing infrastructure. Today’s challenges of scale echo many of the same fundamental questions about computation, data, and learning methods that rese","1.3.5 Deep Learning Era (part 12)"
138,"archers have grappled with since the field’s inception, but now within a more complex and interconnected framework.As AI progressed from symbolic reasoning to statistical learning and deep learning, its applications became increasingly ambitious and complex. This growth introduced challenges that extended beyond algorithms, necessitating a new focus: engineering entire systems capable of deploying and sustaining AI at scale.","1.3.5 Deep Learning Era (part 13)"
139,"This gave rise to the discipline of Machine Learning Systems Engineering.","1.3.5 Deep Learning Era (part 14)"
14,"What to ExpectThis textbook explores the foundational principles, practical workflows, and critical challenges of building and deploying machine learning systems. Starting with foundational concepts, it progresses through engineering principles, examines operational considerations for deploying AI systems, and concludes by reflecting on the societal and technological implications of machine learning.","About the Book (part 3)"
140,"The story we’ve traced—from the early days of the Perceptron through the deep learning revolution—has largely been one of algorithmic breakthroughs. Each era brought new mathematical insights and modeling approaches that pushed the boundaries of what AI could achieve. But something important changed over the past decade: the success of AI systems became increasingly dependent not just on algorithmic innovations, but on sophisticated engineering.","1.4 ML Systems Engineering (part 1)"
141,"This shift mirrors the evolution of computer science and engineering in the late 1960s and early 1970s. During that period, as computing systems grew more complex, a new discipline emerged: Computer Engineering. This field bridged the gap between Electrical Engineering’s hardware expertise and Computer Science’s focus on algorithms and software. Computer Engineering arose because the challenges of designing and building complex computing systems required an integrated approach that neither dis","1.4 ML Systems Engineering (part 2)"
142,"cipline could fully address on its own.Today, we’re witnessing a similar transition in the field of AI. While Computer Science continues to push the boundaries of ML algorithms and Electrical Engineering advances specialized AI hardware, neither discipline fully addresses the engineering principles needed to deploy, optimize, and sustain ML systems at scale. This gap highlights the need for a new discipline: Machine Learning Systems Engineering.","1.4 ML Systems Engineering (part 3)"
143,"There is no explicit definition of what this field is as such today, but it can be broadly defined as such:Definition of Machine Learning Systems EngineeringMachine Learning Systems Engineering (MLSysEng) is the discipline of designing, implementing, and operating artificially intelligent systems across computing scales—from resource-constrained embedded devices to warehouse-scale computers. This field integrates principles from engineering disciplines spanning hardware to software to creat","1.4 ML Systems Engineering (part 4)"
144,"e systems that are reliable, efficient, and optimized for their deployment context. It encompasses the complete lifecycle of AI applications: from requirements engineering and data collection through model development, system integration, deployment, monitoring, and maintenance. The field emphasizes engineering principles of systematic design, resource constraints, performance requirements, and operational reliability.Let’s consider space exploration.","1.4 ML Systems Engineering (part 5)"
145,"While astronauts venture into new frontiers and explore the vast unknowns of the universe, their discoveries are only possible because of the complex engineering systems supporting them—the rockets that lift them into space, the life support systems that keep them alive, and the communication networks that keep them connected to Earth. Similarly, while AI researchers push the boundaries of what’s possible with learning algorithms, their breakthroughs only become practical reality through carefu","1.4 ML Systems Engineering (part 6)"
146,"l systems engineering. Modern AI systems need robust infrastructure to collect and manage data, powerful computing systems to train models, and reliable deployment platforms to serve millions of users.This emergence of machine learning systems engineering as a important discipline reflects a broader reality: turning AI algorithms into real-world systems requires bridging the gap between theoretical possibilities and practical implementation.","1.4 ML Systems Engineering (part 7)"
147,"It’s not enough to have a brilliant algorithm if you can’t efficiently collect and process the data it needs, distribute its computation across hundreds of machines, serve it reliably to millions of users, or monitor its performance in production.Understanding this interplay between algorithms and engineering has become fundamental for modern AI practitioners. While researchers continue to push the boundaries of what’s algorithmically possible, engineers are tackling the complex challenge of","1.4 ML Systems Engineering (part 8)"
148,"making these algorithms work reliably and efficiently in the real world. This brings us to a fundamental question: what exactly is a machine learning system, and what makes it different from traditional software systems?","1.4 ML Systems Engineering (part 9)"
149,"There’s no universally accepted, clear-cut textbook definition of a machine learning system. This ambiguity stems from the fact that different practitioners, researchers, and industries often refer to machine learning systems in varying contexts and with different scopes. Some might focus solely on the algorithmic aspects, while others might include the entire pipeline from data collection to model deployment.","1.5 Defining ML Systems (part 1)"
15,"Learning GoalsKey Learning OutcomesThis book is structured with Bloom’s Taxonomy in mind, which defines six levels of learning, ranging from foundational knowledge to advanced creative thinking:Figure 1: Bloom’s Taxonomy (2021 edition).Remembering: Recalling basic facts and concepts.Understanding: Explaining ideas or processes.Applying: Using knowledge in new situations.Analyzing: Breaking down information into components.","About the Book (part 4)"
150,"This loose usage of the term reflects the rapidly evolving and multidisciplinary nature of the field.Given this diversity of perspectives, it is important to establish a clear and comprehensive definition that encompasses all these aspects. In this textbook, we take a holistic approach to machine learning systems, considering not just the algorithms but also the entire ecosystem in which they operate.","1.5 Defining ML Systems (part 2)"
151,"Therefore, we define a machine learning system as follows:Definition of a Machine Learning SystemA machine learning system is an integrated computing system comprising three core components: (1) data that guides algorithmic behavior, (2) learning algorithms that extract patterns from this data, and (3) computing infrastructure that enables both the learning process (i.e., training) and the application of learned knowledge (i.e., inference/serving).","1.5 Defining ML Systems (part 3)"
152,"Together, these components create a computing system capable of making predictions, generating content, or taking actions based on learned patterns.The core of any machine learning system consists of three interrelated components, as illustrated in Figure 1.3: Models/Algorithms, Data, and Computing Infrastructure. These components form a triangular dependency where each element fundamentally shapes the possibilities of the others.","1.5 Defining ML Systems (part 4)"
153,"The model architecture dictates both the computational demands for training and inference, as well as the volume and structure of data required for effective learning. The data’s scale and complexity influence what infrastructure is needed for storage and processing, while simultaneously determining which model architectures are feasible. The infrastructure capabilities establish practical limits on both model scale and data processing capacity, creating a framework within which the other compo","1.5 Defining ML Systems (part 5)"
154,"nents must operate.Figure 1.3: Machine learning systems involve algorithms, data, and computation, all intertwined together.Each of these components serves a distinct but interconnected purpose:Algorithms: Mathematical models and methods that learn patterns from data to make predictions or decisionsData: Processes and infrastructure for collecting, storing, processing, managing, and serving data for both training and inference.","1.5 Defining ML Systems (part 6)"
155,"Computing: Hardware and software infrastructure that enables efficient training, serving, and operation of models at scale.The interdependency of these components means no single element can function in isolation. The most sophisticated algorithm cannot learn without data or computing resources to run on. The largest datasets are useless without algorithms to extract patterns or infrastructure to process them.","1.5 Defining ML Systems (part 7)"
156,"And the most powerful computing infrastructure serves no purpose without algorithms to execute or data to process.To illustrate these relationships, we can draw an analogy to space exploration. Algorithm developers are like astronauts—exploring new frontiers and making discoveries. Data science teams function like mission control specialists—ensuring the constant flow of critical information and resources needed to keep the mission running.","1.5 Defining ML Systems (part 8)"
157,"Computing infrastructure engineers are like rocket engineers—designing and building the systems that make the mission possible. Just as a space mission requires the seamless integration of astronauts, mission control, and rocket systems, a machine learning system demands the careful orchestration of algorithms, data, and computing infrastructure.","1.5 Defining ML Systems (part 9)"
158,"Traditional software systems follow a predictable lifecycle where developers write explicit instructions for computers to execute. These systems are built on decades of established software engineering practices. Version control systems maintain precise histories of code changes. Continuous integration and deployment pipelines automate testing and release processes. Static analysis tools measure code quality and identify potential issues.","1.6 Lifecycle of ML Systems (part 1)"
159,"This infrastructure enables reliable development, testing, and deployment of software systems, following well-defined principles of software engineering.Machine learning systems represent a fundamental departure from this traditional paradigm. While traditional systems execute explicit programming logic, machine learning systems derive their behavior from patterns in data. This shift from code to data as the primary driver of system behavior introduces new complexities.","1.6 Lifecycle of ML Systems (part 2)"
16,"Evaluating: Making judgments based on criteria and standards.Creating: Producing original work or solutions.Learning ObjectivesThis book supports readers in:Understanding Fundamentals: Explain the foundational principles of machine learning, including theoretical underpinnings and practical applications.Analyzing System Components: Evaluate the critical components of AI systems and their roles within various architectures.","About the Book (part 5)"
160,"As illustrated in Figure 1.4, the ML lifecycle consists of interconnected stages from data collection through model monitoring, with feedback loops for continuous improvement when performance degrades or models need enhancement.Figure 1.4: The typical lifecycle of a machine learning system.Unlike source code, which changes only when developers modify it, data reflects the dynamic nature of the real world. Changes in data distributions can silently alter system behavior.","1.6 Lifecycle of ML Systems (part 3)"
161,"Traditional software engineering tools, designed for deterministic code-based systems, prove insufficient for managing these data-dependent systems. For example, version control systems that excel at tracking discrete code changes struggle to manage large, evolving datasets. Testing frameworks designed for deterministic outputs must be adapted for probabilistic predictions. This data-dependent nature creates a more dynamic lifecycle, requiring continuous monitoring and adaptation to maintain sy","1.6 Lifecycle of ML Systems (part 4)"
162,"stem relevance as real-world data patterns evolve.Understanding the machine learning system lifecycle requires examining its distinct stages. Each stage presents unique requirements from both learning and infrastructure perspectives. This dual consideration—of learning needs and systems support—is wildly important for building effective machine learning systems.However, the various stages of the ML lifecycle in production are not isolated; they are, in fact, deeply interconnected.","1.6 Lifecycle of ML Systems (part 5)"
163,"This interconnectedness can create either virtuous or vicious cycles. In a virtuous cycle, high-quality data enables effective learning, robust infrastructure supports efficient processing, and well-engineered systems facilitate the collection of even better data. However, in a vicious cycle, poor data quality undermines learning, inadequate infrastructure hampers processing, and system limitations prevent the improvement of data collection—each problem compounds the others.","1.6 Lifecycle of ML Systems (part 6)"
164,"The complexity of managing machine learning systems becomes even more apparent when we consider the broad spectrum across which ML is deployed today. ML systems exist at vastly different scales and in diverse environments, each presenting unique challenges and constraints.At one end of the spectrum, we have cloud-based ML systems running in massive data centers. These systems, like large language models or recommendation engines, process petabytes of data and serve millions of users simultaneo","1.7 ML Systems in the Wild (part 1)"
165,"usly. They can leverage virtually unlimited computing resources but must manage enormous operational complexity and costs.At the other end, we find TinyML systems running on microcontrollers and embedded devices. These systems must perform ML tasks with severe constraints on memory, computing power, and energy consumption. Imagine a smart home device, such as Alexa or Google Assistant, that must recognize voice commands using less power than a LED bulb, or a sensor that must detect anomalies w","1.7 ML Systems in the Wild (part 2)"
166,"hile running on a battery for months or even years.Between these extremes, we find a rich variety of ML systems adapted for different contexts. Edge ML systems bring computation closer to data sources, reducing latency and bandwidth requirements while managing local computing resources. Mobile ML systems must balance sophisticated capabilities with battery life and processor limitations on smartphones and tablets.","1.7 ML Systems in the Wild (part 3)"
167,"Enterprise ML systems often operate within specific business constraints, focusing on particular tasks while integrating with existing infrastructure. Some organizations employ hybrid approaches, distributing ML capabilities across multiple tiers to balance various requirements.","1.7 ML Systems in the Wild (part 4)"
168,"The diversity of ML systems across the spectrum represents a complex interplay of requirements, constraints, and trade-offs. These decisions fundamentally impact every stage of the ML lifecycle we discussed earlier, from data collection to continuous operation.Performance requirements often drive initial architectural decisions. Latency-sensitive applications, like autonomous vehicles or real-time fraud detection, might require edge or embedded architectures despite their resource constraints.","1.8 ML Systems Impact on Lifecycle (part 1)"
169,"Conversely, applications requiring massive computational power for training, such as large language models, naturally gravitate toward centralized cloud architectures. However, raw performance is just one consideration in a complex decision space.Resource management varies dramatically across architectures. Cloud systems must optimize for cost efficiency at scale—balancing expensive GPU clusters, storage systems, and network bandwidth.","1.8 ML Systems Impact on Lifecycle (part 2)"
17,"Designing Workflows: Outline workflows for developing machine learning systems, from data collection to deployment.Optimizing Models: Apply methods to enhance performance, such as hyperparameter tuning and regularization.Evaluating Ethical Implications: Analyze societal impacts and address potential biases in AI systems.Exploring Applications: Investigate real-world use cases across diverse domains.","About the Book (part 6)"
170,"Edge systems face fixed resource limits and must carefully manage local compute and storage. Mobile and embedded systems operate under the strictest constraints, where every byte of memory and milliwatt of power matters. These resource considerations directly influence both model design and system architecture.Operational complexity increases with system distribution. While centralized cloud architectures benefit from mature deployment tools and managed services, edge and hybrid systems must","1.8 ML Systems Impact on Lifecycle (part 3)"
171,"handle the complexity of distributed system management. This complexity manifests throughout the ML lifecycle—from data collection and version control to model deployment and monitoring. This operational complexity can compound over time if not carefully managed.Data considerations often introduce competing pressures. Privacy requirements or data sovereignty regulations might push toward edge or embedded architectures, while the need for large-scale training data might favor cloud approaches.","1.8 ML Systems Impact on Lifecycle (part 4)"
172,"The velocity and volume of data also influence architectural choices—real-time sensor data might require edge processing to manage bandwidth, while batch analytics might be better suited to cloud processing.Evolution and maintenance requirements must be considered from the start. Cloud architectures offer flexibility for system evolution but can incur significant ongoing costs. Edge and embedded systems might be harder to update but could offer lower operational overhead.","1.8 ML Systems Impact on Lifecycle (part 5)"
173,"The continuous cycle of ML systems we discussed earlier becomes particularly challenging in distributed architectures, where updating models and maintaining system health requires careful orchestration across multiple tiers.These trade-offs are rarely simple binary choices. Modern ML systems often adopt hybrid approaches, carefully balancing these considerations based on specific use cases and constraints.","1.8 ML Systems Impact on Lifecycle (part 6)"
174,"The key is understanding how these decisions will impact the system throughout its lifecycle, from initial development through continuous operation and evolution.","1.8 ML Systems Impact on Lifecycle (part 7)"
175,"The landscape of machine learning systems is evolving rapidly, with innovations happening from user-facing applications down to core infrastructure. These changes are reshaping how we design and deploy ML systems.Application-Level InnovationThe rise of agentic systems marks a profound shift from traditional reactive ML systems that simply made predictions based on input data. Modern applications can now take actions, learn from outcomes, and adapt their behavior accordingly through multi-agen","1.8.1 Emerging Trends (part 1)"
176,"t systems and advanced planning algorithms. These autonomous agents can plan, reason, and execute complex tasks, introducing new requirements for decision-making frameworks and safety constraints.This increased sophistication extends to operational intelligence. Applications will likely incorporate sophisticated self-monitoring, automated resource management, and adaptive deployment strategies. They can automatically handle data distribution shifts, model updates, and system optimization, mark","1.8.1 Emerging Trends (part 2)"
177,"ing a significant advance in autonomous operation.System Architecture EvolutionSupporting these advanced applications requires fundamental changes in the underlying system architecture. Integration frameworks are evolving to handle increasingly complex interactions between ML systems and broader technology ecosystems. Modern ML systems must seamlessly connect with existing software, process diverse data sources, and operate across organizational boundaries, driving new approaches to system de","1.8.1 Emerging Trends (part 3)"
178,"sign.Resource efficiency has become a central architectural concern as ML systems scale. Innovation in model compression and efficient training techniques is being driven by both environmental and economic factors. Future architectures must carefully balance the pursuit of more powerful models against growing sustainability concerns.At the infrastructure level, new hardware is reshaping deployment possibilities.","1.8.1 Emerging Trends (part 4)"
179,"Specialized AI accelerators are emerging across the spectrum—from powerful data center chips to efficient edge processors to tiny neural processing units in mobile devices. This heterogeneous computing landscape enables dynamic model distribution across tiers based on computing capabilities and conditions, blurring traditional boundaries between cloud, edge, and embedded systems.These trends are creating ML systems that are more capable and efficient while managing increasing complexity.","1.8.1 Emerging Trends (part 5)"
18,"Considering Deployment Challenges: Address security, scalability, and maintainability in real-world systems.Envisioning Future Trends: Reflect on emerging challenges and technologies in machine learning.AI Learning CompanionThroughout this resource, you’ll find SocratiQ—an AI learning assistant designed to enhance your learning experience. Inspired by the Socratic method of teaching, SocratiQ combines interactive quizzes, personalized assistance, and real-time feedback to help you reinfor","About the Book (part 7)"
180,"Success in this evolving landscape requires understanding how application requirements flow down to infrastructure decisions, ensuring systems can grow sustainably while delivering increasingly sophisticated capabilities.","1.8.1 Emerging Trends (part 6)"
181,"The diverse architectures and scales of ML systems demonstrate their potential to revolutionize industries. By examining real-world applications, we can see how these systems address practical challenges and drive innovation. Their ability to operate effectively across varying scales and environments has already led to significant changes in numerous sectors. This section highlights examples where theoretical concepts and practical considerations converge to produce tangible, impactful results.","1.9 Practical Applications"
182,"FarmBeats, a project developed by Microsoft Research, shown in Figure 1.5 is a significant advancement in the application of machine learning to agriculture. This system aims to increase farm productivity and reduce costs by leveraging AI and IoT technologies. FarmBeats exemplifies how edge and embedded ML systems can be deployed in challenging, real-world environments to solve practical problems. By bringing ML capabilities directly to the farm, FarmBeats demonstrates the potential of distribut","1.9.1 FarmBeats: ML in Agriculture (part 1)"
183,"ed AI systems in transforming traditional industries.Figure 1.5: Microsoft FarmBeats: AI, Edge & IoT for Agriculture.Data ConsiderationsThe data ecosystem in FarmBeats is diverse and distributed. Sensors deployed across fields collect real-time data on soil moisture, temperature, and nutrient levels. Drones equipped with multispectral cameras capture high-resolution imagery of crops, providing insights into plant health and growth patterns.","1.9.1 FarmBeats: ML in Agriculture (part 2)"
184,"Weather stations contribute local climate data, while historical farming records offer context for long-term trends. The challenge lies not just in collecting this heterogeneous data, but in managing its flow from dispersed, often remote locations with limited connectivity. FarmBeats employs innovative data transmission techniques, such as using TV white spaces (unused broadcasting frequencies) to extend internet connectivity to far-flung sensors.","1.9.1 FarmBeats: ML in Agriculture (part 3)"
185,"This approach to data collection and transmission embodies the principles of edge computing we discussed earlier, where data processing begins at the source to reduce bandwidth requirements and enable real-time decision making.Algorithmic ConsiderationsFarmBeats uses a variety of ML algorithms tailored to agricultural applications. For soil moisture prediction, it uses temporal neural networks that can capture the complex dynamics of water movement in soil.","1.9.1 FarmBeats: ML in Agriculture (part 4)"
186,"Computer vision algorithms process drone imagery to detect crop stress, pest infestations, and yield estimates. These models must be robust to noisy data and capable of operating with limited computational resources. Machine learning methods such as “transfer learning” allow models to learn on data-rich farms to be adapted for use in areas with limited historical data. The system also incorporates a mixture of methods that combine outputs from multiple algorithms to improve prediction accuracy","1.9.1 FarmBeats: ML in Agriculture (part 5)"
187,"and reliability. A key challenge FarmBeats addresses is model personalization—adapting general models to the specific conditions of individual farms, which may have unique soil compositions, microclimates, and farming practices.Infrastructure ConsiderationsFarmBeats exemplifies the edge computing paradigm we explored in our discussion of the ML system spectrum. At the lowest level, embedded ML models run directly on IoT devices and sensors, performing basic data filtering and anomaly detectio","1.9.1 FarmBeats: ML in Agriculture (part 6)"
188,"n. Edge devices, such as ruggedized field gateways, aggregate data from multiple sensors and run more complex models for local decision-making. These edge devices operate in challenging conditions, requiring robust hardware designs and efficient power management to function reliably in remote agricultural settings. The system employs a hierarchical architecture, with more computationally intensive tasks offloaded to on-premises servers or the cloud.","1.9.1 FarmBeats: ML in Agriculture (part 7)"
189,"This tiered approach allows FarmBeats to balance the need for real-time processing with the benefits of centralized data analysis and model training. The infrastructure also includes mechanisms for over-the-air model updates, ensuring that edge devices can receive improved models as more data becomes available and algorithms are refined.Future ImplicationsFarmBeats shows how ML systems can be deployed in resource-constrained, real-world environments to drive significant improvements in tradi","1.9.1 FarmBeats: ML in Agriculture (part 8)"
19,"ce your understanding and create new connections. As part of our experiment with Generative AI technologies, SocratiQ encourages critical thinking and active engagement with the material.SocratiQ is still a work in progress, and we welcome your feedback to make it better. For more details about how SocratiQ works and how to get the most out of it, visit the AI Learning Companion page.How to Use This BookBook StructureThe book is organized into four main parts, each building on the previous","About the Book (part 8)"
190,"tional industries. By providing farmers with AI-driven insights, the system has shown potential to increase crop yields, reduce water usage, and optimize resource allocation. Looking forward, the FarmBeats approach could be extended to address global challenges in food security and sustainable agriculture. The success of this system also highlights the growing importance of edge and embedded ML in IoT applications, where bringing intelligence closer to the data source can lead to more responsive","1.9.1 FarmBeats: ML in Agriculture (part 9)"
191,", efficient, and scalable solutions. As edge computing capabilities continue to advance, we can expect to see similar distributed ML architectures applied to other domains, from smart cities to environmental monitoring.","1.9.1 FarmBeats: ML in Agriculture (part 10)"
192,"AlphaFold, developed by DeepMind, is a landmark achievement in the application of machine learning to complex scientific problems. This AI system is designed to predict the three-dimensional structure of proteins, as shown in Figure 1.6, from their amino acid sequences, a challenge known as the “protein folding problem” that has puzzled scientists for decades. AlphaFold’s success demonstrates how large-scale ML systems can accelerate scientific discovery and potentially revolutionize fields like","1.9.2 AlphaFold: Scientific ML (part 1)"
193,"structural biology and drug design. This case study exemplifies the use of advanced ML techniques and massive computational resources to tackle problems at the frontiers of science.Figure 1.6: Examples of protein targets within the free modeling category. Source: Google DeepMindData ConsiderationsThe data underpinning AlphaFold’s success is vast and multifaceted. The primary dataset is the Protein Data Bank (PDB), which contains the experimentally determined structures of over 180,000 prot","1.9.2 AlphaFold: Scientific ML (part 2)"
194,"eins. This is complemented by databases of protein sequences, which number in the hundreds of millions. AlphaFold also utilizes evolutionary data in the form of multiple sequence alignments (MSAs), which provide insights into the conservation patterns of amino acids across related proteins. The challenge lies not just in the volume of data, but in its quality and representation. Experimental protein structures can contain errors or be incomplete, requiring sophisticated data cleaning and validat","1.9.2 AlphaFold: Scientific ML (part 3)"
195,"ion processes. Moreover, the representation of protein structures and sequences in a form amenable to machine learning is a significant challenge in itself. AlphaFold’s data pipeline involves complex preprocessing steps to convert raw sequence and structural data into meaningful features that capture the physical and chemical properties relevant to protein folding.Algorithmic ConsiderationsAlphaFold’s algorithmic approach represents a tour de force in the application of deep learning to scien","1.9.2 AlphaFold: Scientific ML (part 4)"
196,"tific problems. At its core, AlphaFold uses a novel neural network architecture that combines with techniques from computational biology. The model learns to predict inter-residue distances and torsion angles, which are then used to construct a full 3D protein structure. A key innovation is the use of “equivariant attention” layers that respect the symmetries inherent in protein structures. The learning process involves multiple stages, including initial “pretraining” on a large corpus of protei","1.9.2 AlphaFold: Scientific ML (part 5)"
197,"n sequences, followed by fine-tuning on known structures. AlphaFold also incorporates domain knowledge in the form of physics-based constraints and scoring functions, creating a hybrid system that leverages both data-driven learning and scientific prior knowledge. The model’s ability to generate accurate confidence estimates for its predictions is crucial, allowing researchers to assess the reliability of the predicted structures.","1.9.2 AlphaFold: Scientific ML (part 6)"
198,"Infrastructure ConsiderationsThe computational demands of AlphaFold epitomize the challenges of large-scale scientific ML systems. Training the model requires massive parallel computing resources, leveraging clusters of GPUs or TPUs (Tensor Processing Units) in a distributed computing environment. DeepMind utilized Google’s cloud infrastructure, with the final version of AlphaFold trained on 128 TPUv3 cores for several weeks.","1.9.2 AlphaFold: Scientific ML (part 7)"
199,"The inference process, while less computationally intensive than training, still requires significant resources, especially when predicting structures for large proteins or processing many proteins in parallel. To make AlphaFold more accessible to the scientific community, DeepMind has collaborated with the European Bioinformatics Institute to create a public database of predicted protein structures, which itself represents a substantial computing and data management challenge.","1.9.2 AlphaFold: Scientific ML (part 8)"
2,"Author’s NoteAI is bound to transform the world in profound ways, much like computers and the Internet revolutionized every aspect of society in the 20th century. From systems that generate creative content to those driving breakthroughs in drug discovery, AI is ushering in a new era—one that promises to be even more transformative in its scope and impact. But how do we make it accessible to everyone?","Author’s Note (part 1)"
20,"one:The Essentials (Chapters 1-4) Core principles, components, and architectures that underpin machine learning systems.Engineering Principles (Chapters 5-13) Covers workflows, data engineering, optimization strategies, and operational challenges in system design.AI Best Practice (Chapters 14-18) Focuses on key considerations for deploying AI systems in real-world environments, including security, privacy, robustness, and sustainability.","About the Book (part 9)"
200,"This infrastructure allows researchers worldwide to access AlphaFold’s predictions without needing to run the model themselves, demonstrating how centralized, high-performance computing resources can be leveraged to democratize access to advanced ML capabilities.Future ImplicationsAlphaFold’s impact on structural biology has been profound, with the potential to accelerate research in areas ranging from fundamental biology to drug discovery.","1.9.2 AlphaFold: Scientific ML (part 9)"
201,"By providing accurate structural predictions for proteins that have resisted experimental methods, AlphaFold opens new avenues for understanding disease mechanisms and designing targeted therapies. The success of AlphaFold also serves as a powerful demonstration of how ML can be applied to other complex scientific problems, potentially leading to breakthroughs in fields like materials science or climate modeling.","1.9.2 AlphaFold: Scientific ML (part 10)"
202,"However, it also raises important questions about the role of AI in scientific discovery and the changing nature of scientific inquiry in the age of large-scale ML systems. As we look to the future, the AlphaFold approach suggests a new paradigm for scientific ML, where massive computational resources are combined with domain-specific knowledge to push the boundaries of human understanding.","1.9.2 AlphaFold: Scientific ML (part 11)"
203,"Waymo, a subsidiary of Alphabet Inc., stands at the forefront of autonomous vehicle technology, representing one of the most ambitious applications of machine learning systems to date. Evolving from the Google Self-Driving Car Project initiated in 2009, Waymo’s approach to autonomous driving exemplifies how ML systems can span the entire spectrum from embedded systems to cloud infrastructure. This case study demonstrates the practical implementation of complex ML systems in a safety-critical, re","1.9.3 Autonomous Vehicles and ML (part 1)"
204,"al-world environment, integrating real-time decision-making with long-term learning and adaptation.Data ConsiderationsThe data ecosystem underpinning Waymo’s technology is vast and dynamic. Each vehicle serves as a roving data center, its sensor suite—comprising LiDAR, radar, and high-resolution cameras—generating approximately one terabyte of data per hour of driving. This real-world data is complemented by an even more extensive simulated dataset, with Waymo’s vehicles having traversed over","1.9.3 Autonomous Vehicles and ML (part 2)"
205,"20 billion miles in simulation and more than 20 million miles on public roads. The challenge lies not just in the volume of data, but in its heterogeneity and the need for real-time processing. Waymo must handle both structured (e.g., GPS coordinates) and unstructured data (e.g., camera images) simultaneously. The data pipeline spans from edge processing on the vehicle itself to massive cloud-based storage and processing systems.","1.9.3 Autonomous Vehicles and ML (part 3)"
206,"Sophisticated data cleaning and validation processes are necessary, given the safety-critical nature of the application. Moreover, the representation of the vehicle’s environment in a form amenable to machine learning presents significant challenges, requiring complex preprocessing to convert raw sensor data into meaningful features that capture the dynamics of traffic scenarios.Algorithmic ConsiderationsWaymo’s ML stack represents a sophisticated ensemble of algorithms tailored to the multi","1.9.3 Autonomous Vehicles and ML (part 4)"
207,"faceted challenge of autonomous driving. The perception system employs deep learning techniques, including convolutional neural networks, to process visual data for object detection and tracking. Prediction models, needed for anticipating the behavior of other road users, leverage recurrent neural networks (RNNs) to understand temporal sequences. Waymo has developed custom ML models like VectorNet for predicting vehicle trajectories.","1.9.3 Autonomous Vehicles and ML (part 5)"
208,"The planning and decision-making systems may incorporate reinforcement learning or imitation learning techniques to navigate complex traffic scenarios. A key innovation in Waymo’s approach is the integration of these diverse models into a coherent system capable of real-time operation. The ML models must also be interpretable to some degree, as understanding the reasoning behind a vehicle’s decisions is vital for safety and regulatory compliance.","1.9.3 Autonomous Vehicles and ML (part 6)"
209,"Waymo’s learning process involves continuous refinement based on real-world driving experiences and extensive simulation, creating a feedback loop that constantly improves the system’s performance.Infrastructure ConsiderationsThe computing infrastructure supporting Waymo’s autonomous vehicles epitomizes the challenges of deploying ML systems across the full spectrum from edge to cloud. Each vehicle is equipped with a custom-designed compute platform capable of processing sensor data and maki","1.9.3 Autonomous Vehicles and ML (part 7)"
21,"Closing Perspectives (Chapter 19-20) Synthesizes key lessons and explores emerging trends shaping the future of ML systems.Suggested Reading PathsBeginners: Start with The Essentials to build a strong conceptual base before progressing to other parts.Practitioners: Focus on Engineering Principles and AI in Practice for hands-on, real-world insights.Researchers: Dive into AI in Practice and Closing Perspectives to explore advanced topics and societal implications.","About the Book (part 10)"
210,"ng decisions in real-time, often leveraging specialized hardware like GPUs or tensor processing units (TPUs). This edge computing is complemented by extensive use of cloud infrastructure, leveraging the power of Google’s data centers for training models, running large-scale simulations, and performing fleet-wide learning. The connectivity between these tiers is critical, with vehicles requiring reliable, high-bandwidth communication for real-time updates and data uploading.","1.9.3 Autonomous Vehicles and ML (part 8)"
211,"Waymo’s infrastructure must be designed for robustness and fault tolerance, ensuring safe operation even in the face of hardware failures or network disruptions. The scale of Waymo’s operation presents significant challenges in data management, model deployment, and system monitoring across a geographically distributed fleet of vehicles.Future ImplicationsWaymo’s impact extends beyond technological advancement, potentially revolutionizing transportation, urban planning, and numerous aspects","1.9.3 Autonomous Vehicles and ML (part 9)"
212,"of daily life. The launch of Waymo One, a commercial ride-hailing service using autonomous vehicles in Phoenix, Arizona, represents a significant milestone in the practical deployment of AI systems in safety-critical applications. Waymo’s progress has broader implications for the development of robust, real-world AI systems, driving innovations in sensor technology, edge computing, and AI safety that have applications far beyond the automotive industry.","1.9.3 Autonomous Vehicles and ML (part 10)"
213,"However, it also raises important questions about liability, ethics, and the interaction between AI systems and human society. As Waymo continues to expand its operations and explore applications in trucking and last-mile delivery, it serves as an important test bed for advanced ML systems, driving progress in areas such as continual learning, robust perception, and human-AI interaction. The Waymo case study underscores both the tremendous potential of ML systems to transform industries and the","1.9.3 Autonomous Vehicles and ML (part 11)"
214,"complex challenges involved in deploying AI in the real world.","1.9.3 Autonomous Vehicles and ML (part 12)"
215,"Building and deploying machine learning systems presents unique challenges that go beyond traditional software development. These challenges help explain why creating effective ML systems is about more than just choosing the right algorithm or collecting enough data. Let’s explore the key areas where ML practitioners face significant hurdles.","1.10 Challenges in ML Systems"
216,"The foundation of any ML system is its data, and managing this data introduces several fundamental challenges. First, there’s the basic question of data quality—real-world data is often messy and inconsistent. Imagine a healthcare application that needs to process patient records from different hospitals. Each hospital might record information differently, use different units of measurement, or have different standards for what data to collect.","1.10.1 Data-Related Challenges (part 1)"
217,"Some records might have missing information, while others might contain errors or inconsistencies that need to be cleaned up before the data can be useful.As ML systems grow, they often need to handle increasingly large amounts of data. A video streaming service like Netflix, for example, needs to process billions of viewer interactions to power its recommendation system. This scale introduces new challenges in how to store, process, and manage such large datasets efficiently.","1.10.1 Data-Related Challenges (part 2)"
218,"Another critical challenge is how data changes over time. This phenomenon, known as “data drift”, occurs when the patterns in new data begin to differ from the patterns the system originally learned from. For example, many predictive models struggled during the COVID-19 pandemic because consumer behavior changed so dramatically that historical patterns became less relevant. ML systems need ways to detect when this happens and adapt accordingly.","1.10.1 Data-Related Challenges (part 3)"
219,"Creating and maintaining the ML models themselves presents another set of challenges. Modern ML models, particularly in deep learning, can be extremely complex. Consider a language model like GPT-3, which has hundreds of billions of parameters that need to be optimized through backpropagation. This complexity creates practical challenges: these models require enormous computing power to train and run, making it difficult to deploy them in situations with limited resources, like on mobile phones","1.10.2 Model-Related Challenges (part 1)"
22,"Modular DesignThe book is modular, allowing readers to explore chapters independently or sequentially. Each chapter includes supplementary resources:Slides summarizing key concepts.Videos providing in-depth explanations.Exercises reinforcing understanding.Labs offering practical, hands-on experience.While several of these resources are still a work in progress, we believe it’s better to share valuable insights and tools as they become available rather than wait for everything to be","About the Book (part 11)"
220,"or IoT devices.Training these models effectively is itself a significant challenge. Unlike traditional programming where we write explicit instructions, ML models learn from examples through techniques like transfer learning. This learning process involves many choices: How should we structure the model? How long should we train it? How can we tell if it’s learning the right things? Making these decisions often requires both technical expertise and considerable trial and error.","1.10.2 Model-Related Challenges (part 2)"
221,"A particularly important challenge is ensuring that models work well in real-world conditions. A model might perform excellently on its training data but fail when faced with slightly different situations in the real world. This gap between training performance and real-world performance is a central challenge in machine learning, especially for critical applications like autonomous vehicles or medical diagnosis systems.","1.10.2 Model-Related Challenges (part 3)"
222,"Getting ML systems to work reliably in the real world introduces its own set of challenges. Unlike traditional software that follows fixed rules, ML systems need to handle uncertainty and variability in their inputs and outputs. They also typically need both training systems (for learning from data) and serving systems (for making predictions), each with different requirements and constraints.Consider a company building a speech recognition system.","1.10.3 System-Related Challenges (part 1)"
223,"They need infrastructure to collect and store audio data, systems to train models on this data, and then separate systems to actually process users’ speech in real-time. Each part of this pipeline needs to work reliably and efficiently, and all the parts need to work together seamlessly.These systems also need constant monitoring and updating. How do we know if the system is working correctly? How do we update models without interrupting service? How do we handle errors or unexpected inputs?","1.10.3 System-Related Challenges (part 2)"
224,"These operational challenges become particularly complex when ML systems are serving millions of users.","1.10.3 System-Related Challenges (part 3)"
225,"As ML systems become more prevalent in our daily lives, their broader impacts on society become increasingly important to consider. One major concern is fairness—ML systems can sometimes learn to make decisions that discriminate against certain groups of people. This often happens unintentionally, as the systems pick up biases present in their training data. For example, a job application screening system might inadvertently learn to favor certain demographics if those groups were historically m","1.10.4 Ethical Considerations (part 1)"
226,"ore likely to be hired.Another important consideration is transparency. Many modern ML models, particularly deep learning models, work as “black boxes”—while they can make predictions, it’s often difficult to understand how they arrived at their decisions. This becomes particularly problematic when ML systems are making important decisions about people’s lives, such as in healthcare or financial services.Privacy is also a major concern.","1.10.4 Ethical Considerations (part 2)"
227,"ML systems often need large amounts of data to work effectively, but this data might contain sensitive personal information. How do we balance the need for data with the need to protect individual privacy? How do we ensure that models don’t inadvertently memorize and reveal private information through inference attacks? These challenges aren’t merely technical problems to be solved, but ongoing considerations that shape how we approach ML system design and deployment.","1.10.4 Ethical Considerations (part 3)"
228,"These challenges aren’t merely technical problems to be solved, but ongoing considerations that shape how we approach ML system design and deployment. Throughout this book, we’ll explore these challenges in detail and examine strategies for addressing them effectively.","1.10.4 Ethical Considerations (part 4)"
229,"As we look to the future of machine learning systems, several exciting trends are shaping the field. These developments promise to both solve existing challenges and open new possibilities for what ML systems can achieve.One of the most significant trends is the democratization of AI technology. Just as personal computers transformed computing from specialized mainframes to everyday tools, ML systems are becoming more accessible to developers and organizations of all sizes.","1.11 Looking Ahead (part 1)"
23,"as including security, privacy, and reliability. While ML applications and tools evolve rapidly, the engineering principles for building ML systems remain largely consistent. This book distills these enduring concepts, making it a resource for anyone seeking to build flexible, efficient, and robust ML systems.🎙 Listen to the AI Podcast, created using Google’s Notebook LM and inspired by insights drawn from our IEEE education viewpoint paper.","preface (part 3)"
230,"Cloud providers now offer pre-trained models and automated ML platforms that reduce the expertise needed to deploy AI solutions. This democratization is enabling new applications across industries, from small businesses using AI for customer service to researchers applying ML to previously intractable problems.As concerns about computational costs and environmental impact grow, there’s an increasing focus on making ML systems more efficient.","1.11 Looking Ahead (part 2)"
231,"Researchers are developing new techniques for training models with less data and computing power. Innovation in specialized hardware, from improved GPUs to custom AI chips, is making ML systems faster and more energy-efficient. These advances could make sophisticated AI capabilities available on more devices, from smartphones to IoT sensors.Perhaps the most transformative trend is the development of more autonomous ML systems that can adapt and improve themselves.","1.11 Looking Ahead (part 3)"
232,"These systems are beginning to handle their own maintenance tasks—detecting when they need retraining, automatically finding and correcting errors, and optimizing their own performance. This automation could dramatically reduce the operational overhead of running ML systems while improving their reliability.While these trends are promising, it’s important to recognize the field’s limitations. Creating truly artificial general intelligence remains a distant goal.","1.11 Looking Ahead (part 4)"
233,"Current ML systems excel at specific tasks but lack the flexibility and understanding that humans take for granted. Challenges around bias, transparency, and privacy continue to require careful consideration. As ML systems become more prevalent, addressing these limitations while leveraging new capabilities will be crucial.","1.11 Looking Ahead (part 5)"
234,"This book is designed to guide you from understanding the fundamentals of ML systems to effectively designing and implementing them. To address the complexities and challenges of Machine Learning Systems engineering, we’ve organized the content around five fundamental pillars that encompass the lifecycle of ML systems. These pillars provide a framework for understanding, developing, and maintaining robust ML systems.Figure 1.","1.12 Book Structure and Learning Path (part 1)"
235,"7: Overview of the five fundamental system pillars of Machine Learning Systems engineering.As illustrated in Figure 1.7, the five pillars central to the framework are:Data: Emphasizing data engineering and foundational principles critical to how AI operates in relation to data.Training: Exploring the methodologies for AI training, focusing on efficiency, optimization, and acceleration techniques to enhance model performance.","1.12 Book Structure and Learning Path (part 2)"
236,"Deployment: Encompassing benchmarks, on-device learning strategies, and machine learning operations to ensure effective model application.Operations: Highlighting the maintenance challenges unique to machine learning systems, which require specialized approaches distinct from traditional engineering systems.Ethics & Governance: Addressing concerns such as security, privacy, responsible AI practices, and the broader societal implications of AI technologies.","1.12 Book Structure and Learning Path (part 3)"
237,"Each pillar represents a critical phase in the lifecycle of ML systems and is composed of foundational elements that build upon each other. This structure ensures a comprehensive understanding of MLSE, from basic principles to advanced applications and ethical considerations.For more detailed information about the book’s overview, contents, learning outcomes, target audience, prerequisites, and navigation guide, please refer to the About the Book section.","1.12 Book Structure and Learning Path (part 4)"
238,"There, you’ll also find valuable details about our learning community and how to maximize your experience with this resource.","1.12 Book Structure and Learning Path (part 5)"
24,"perfect. After all, progress is far more important than perfection, and your feedback will help us improve and refine this resource over time.Additionally, we try to reuse and build upon the incredible work created by amazing experts in the field, rather than reinventing everything from scratch. This philosophy reflects the fundamental essence of community-driven learning: collaboration, sharing knowledge, and collectively advancing our understanding.","About the Book (part 12)"
25,"Transparency and CollaborationThis book is a community-driven project, with content generated collaboratively by numerous contributors over time. The content creation process may have involved various editing tools, including generative AI technology. As the main author, editor, and curator, Prof. Vijay Janapa Reddi maintains human oversight to ensure the content is accurate and relevant.However, no one is perfect, and inaccuracies may still exist.","About the Book (part 13)"
26,"Your feedback is highly valued, and we encourage you to provide corrections or suggestions. This collaborative approach is crucial for maintaining high-quality information and making it globally accessible.Copyright and LicensingThis book is open-source and developed collaboratively through GitHub. Unless otherwise stated, this work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0).","About the Book (part 14)"
27,"Contributors retain copyright over their individual contributions, dedicated to the public domain or released under the same open license as the original project. For more information on authorship and contributions, visit the GitHub repository.Join the CommunityThis textbook is more than just a resource—it’s an invitation to collaborate and learn together. Engage in community discussions to share insights, tackle challenges, and learn alongside fellow students, researchers, and practitione","About the Book (part 15)"
28,"rs.Whether you’re a student starting your journey, a practitioner solving real-world challenges, or a researcher exploring advanced concepts, your contributions will enrich this learning community. Introduce yourself, share your goals, and let’s collectively build a deeper understanding of machine learning systems.","About the Book (part 16)"
29,"Book ChangelogThis Machine Learning Systems textbook is constantly evolving. This changelog automatically records all updates and improvements, helping you stay informed about what’s new and refined.Last Updated: May 14, 20252025 Changes📅 Published on May 14, 2025🔗 View Full Diff — 1 files updated (39 lines added, 41 lines removed)Minor UpdatesOndevice Learning: ++— (39 lines added, 41 lines removed)📅 Published on May 14, 2025🔗 View Full Diff — 1 files updated (647 lines added, 5","Book Changelog (part 1)"
3,"With its transformative power comes an equally great responsibility for those who access it or work with it. Just as we expect companies to wield their influence ethically, those of us in academia bear a parallel responsibility: to share our knowledge openly, so it benefits everyone—not just a select few. This conviction inspired the creation of this book—an open-source resource aimed at making AI education, particularly in AI engineering, and systems, inclusive, and accessible to everyone fro","Author’s Note (part 2)"
30,"7 lines removed)Major Updates📅 Published on May 04, 2025🔗 View Full Diff — 37 files updated (7185 lines added, 3152 lines removed)Major UpdatesMinor Updates📅 Published on Mar 25, 2025🔗 View Full Diff — 2 files updated (4 lines added, 1 lines removed)Minor Updates📅 Published on Mar 26, 2025🔗 View Full Diff — 40 files updated (12616 lines added, 7370 lines removed)Major UpdatesMinor Updates📅 Published on Mar 03, 2025🔗 View Full Diff — 31 files updated (12032 lines added,","Book Changelog (part 2)"
31,"7337 lines removed)Major UpdatesMinor Updates📅 Published on Feb 08, 2025🔗 View Full Diff — 2 files updated (31 lines added, 29 lines removed)Minor Updates📅 Published on Feb 07, 2025🔗 View Full Diff — 46 files updated (4644 lines added, 3807 lines removed)Major UpdatesMinor Updates📅 Published on Feb 02, 2025🔗 View Full Diff — 20 files updated (2076 lines added, 1555 lines removed)Major UpdatesMinor Updates📅 Published on Jan 28, 2025🔗 View Full Diff — 1 files updated (52","Book Changelog (part 3)"
32,"lines added, 52 lines removed)Minor Updates📅 Published on Jan 28, 2025🔗 View Full Diff — 16 files updated (4127 lines added, 2219 lines removed)Major UpdatesMinor Updates📅 Published on Jan 17, 2025🔗 View Full Diff — 12 files updated (1976 lines added, 1477 lines removed)Major UpdatesMinor Updates📅 Published on Jan 12, 2025🔗 View Full Diff — 5 files updated (221 lines added, 253 lines removed)Major UpdatesMinor Updates📅 Published on Jan 11, 2025🔗 View Full Diff — 4 fil","Book Changelog (part 4)"
33,"es updated (154 lines added, 103 lines removed)Minor Updates📅 Published on Jan 11, 2025🔗 View Full Diff — 5 files updated (907 lines added, 535 lines removed)Major UpdatesMinor Updates📅 Published on Jan 09, 2025🔗 View Full Diff — 8 files updated (56 lines added, 58 lines removed)Minor Updates📅 Published on Jan 07, 2025🔗 View Full Diff — 5 files updated (254 lines added, 149 lines removed)Minor Updates📅 Published on Jan 03, 2025🔗 View Full Diff — 7 files updated (38 lines","Book Changelog (part 5)"
34,"This podcast provides an accessible overview of what this book is all about.  PrefaceCover image.Welcome to Machine Learning Systems, your gateway to the fast-paced world of machine learning (ML) systems. This book is an extension of the CS249r course at Harvard University, taught by Prof. Vijay Janapa Reddi, and is the result of a collaborative effort involving students, professionals, and the broader community of AI practitioners.","preface (part 4)"
35,"added, 36 lines removed)Minor Updates📅 Published on Jan 02, 2025🔗 View Full Diff — 4 files updated (66 lines added, 127 lines removed)Minor Updates📅 Published on Jan 01, 2025🔗 View Full Diff — 45 files updated (8282 lines added, 4753 lines removed)Major UpdatesMinor Updates2024 Changes📅 Published on Nov 19, 2024🔗 View Full Diff — 2 files updated (74 lines added, 65 lines removed)Minor Updates📅 Published on Nov 19, 2024🔗 View Full Diff — 6 files updated (474 lines added","Book Changelog (part 6)"
36,", 331 lines removed)Major UpdatesMinor Updates📅 Published on Nov 16, 2024🔗 View Full Diff — 4 files updated (502 lines added, 106 lines removed)Major UpdatesMinor Updates📅 Published on Nov 15, 2024🔗 View Full Diff — 35 files updated (74 lines added, 162 lines removed)Minor Updates📅 Published on Nov 15, 2024🔗 View Full Diff — 86 files updated (3636 lines added, 1991 lines removed)Major UpdatesMinor Updates📅 Published on Sep 20, 2024🔗 View Full Diff — 1 files updated (1","Book Changelog (part 7)"
37,"lines added, 1 lines removed)Minor Updates📅 Published on Sep 20, 2024🔗 View Full Diff — 43 files updated (4718 lines added, 3227 lines removed)Major UpdatesMinor Updates📅 Published on Sep 12, 2024🔗 View Full Diff — 7 files updated (1561 lines added, 86 lines removed)Major UpdatesMinor Updates📅 Published on Sep 06, 2024🔗 View Full Diff — 1 files updated (8 lines added, 10 lines removed)Minor Updates📅 Published on Sep 04, 2024🔗 View Full Diff — 20 files updated (78 lines","Book Changelog (part 8)"
38,"added, 82 lines removed)Minor Updates📅 Published on Sep 02, 2024🔗 View Full Diff — 5 files updated (218 lines added, 179 lines removed)Minor Updates📅 Published on Aug 29, 2024🔗 View Full Diff — 5 files updated (1568 lines added, 34 lines removed)Major UpdatesMinor Updates📅 Published on Aug 27, 2024🔗 View Full Diff — 10 files updated (225 lines added, 245 lines removed)Major UpdatesMinor Updates📅 Published on Aug 22, 2024🔗 View Full Diff — 6 files updated (14 lines added","Book Changelog (part 9)"
39,", 21 lines removed)Minor Updates📅 Published on Aug 21, 2024🔗 View Full Diff — 18 files updated (720 lines added, 1217 lines removed)Major UpdatesMinor Updates📅 Published on Aug 15, 2024🔗 View Full Diff — 3 files updated (3 lines added, 6 lines removed)Minor Updates📅 Published on Aug 15, 2024🔗 View Full Diff — 22 files updated (363 lines added, 239 lines removed)Minor Updates📅 Published on Aug 15, 2024🔗 View Full Diff — 3 files updated (188 lines added, 164 lines removed)","Book Changelog (part 10)"
4,"m all walks of life.My passion for creating, curating, and editing this content has been deeply influenced by landmark textbooks that have profoundly shaped both my academic and personal journey. Whether I studied them cover to cover or drew insights from key passages, these resources fundamentally shaped the way I think. I reflect on the books that guided my path: works by Turing Award winners such as David Patterson and John Hennessy—pioneers in computer architecture and system design—and fo","Author’s Note (part 3)"
40,"Major UpdatesMinor Updates📅 Published on Aug 06, 2024🔗 View Full Diff — 14 files updated (279 lines added, 279 lines removed)Minor Updates📅 Published on Aug 06, 2024🔗 View Full Diff — 27 files updated (1182 lines added, 810 lines removed)Major UpdatesMinor Updates📅 Published on Jun 25, 2024🔗 View Full Diff — 1 files updated (1 lines added, 1 lines removed)Minor Updates📅 Published on Jun 20, 2024🔗 View Full Diff — 2 files updated (4 lines added, 5 lines removed)Minor U","Book Changelog (part 11)"
41,"pdates📅 Published on Jun 19, 2024🔗 View Full Diff — 58 files updated (6625 lines added, 2899 lines removed)Major UpdatesMinor Updates📅 Published on Jun 11, 2024🔗 View Full Diff — 18 files updated (518 lines added, 204 lines removed)Minor Updates📅 Published on Jun 01, 2024🔗 View Full Diff — 19 files updated (401 lines added, 404 lines removed)Minor Updates📅 Published on May 26, 2024🔗 View Full Diff — 29 files updated (9908 lines added, 8688 lines removed)Major UpdatesMin","Book Changelog (part 12)"
42,"or Updates📅 Published on Mar 21, 2024🔗 View Full Diff — 17 files updated (860 lines added, 374 lines removed)Minor Updates📅 Published on Mar 12, 2024🔗 View Full Diff — 0 files updated (0 lines added, 0 lines removed)📅 Published on Mar 12, 2024🔗 View Full Diff — 18 files updated (606 lines added, 290 lines removed)Minor Updates📅 Published on Feb 03, 2024🔗 View Full Diff — 8 files updated (35 lines added, 35 lines removed)Minor Updates📅 Published on Feb 02, 2024🔗 View Fu","Book Changelog (part 13)"
43,"ll Diff — 14 files updated (310 lines added, 315 lines removed)Minor Updates📅 Published on Jan 02, 2024🔗 View Full Diff — 2 files updated (1 lines added, 3 lines removed)Minor Updates2023 Changes📅 Published on Dec 19, 2023🔗 View Full Diff — 1 files updated (135 lines added, 103 lines removed)Major Updates📅 Published on Dec 18, 2023🔗 View Full Diff — 3 files updated (43 lines added, 19 lines removed)Minor Updates📅 Published on Dec 13, 2023🔗 View Full Diff — 1 files update","Book Changelog (part 14)"
44,"d (1 lines added, 1 lines removed)Minor Updates📅 Published on Dec 13, 2023🔗 View Full Diff — 1 files updated (1 lines added, 1 lines removed)Minor Updates📅 Published on Dec 12, 2023🔗 View Full Diff — 1 files updated (2 lines added, 2 lines removed)Minor Updates📅 Published on Dec 12, 2023🔗 View Full Diff — 2 files updated (2 lines added, 2 lines removed)Minor Updates📅 Published on Dec 12, 2023🔗 View Full Diff — 1 files updated (1 lines added, 1 lines removed)Minor Update","Book Changelog (part 15)"
45,"We’ve created this open-source book to demystify the process of building efficient and scalable ML systems. Our goal is to provide a comprehensive guide that covers the principles, practices, and challenges of developing robust ML pipelines for deployment. This isn’t a static textbook—it’s a living, evolving resource designed to keep pace with advancements in the field.“If you want to go fast, go alone. If you want to go far, go together.","preface (part 5)"
46,"s📅 Published on Dec 11, 2023🔗 View Full Diff — 0 files updated (0 lines added, 0 lines removed)📅 Published on Dec 11, 2023🔗 View Full Diff — 10 files updated (18 lines added, 121 lines removed)Minor Updates📅 Published on Dec 11, 2023🔗 View Full Diff — 10 files updated (36 lines added, 36 lines removed)Minor Updates📅 Published on Dec 11, 2023🔗 View Full Diff — 26 files updated (137 lines added, 32 lines removed)Minor Updates📅 Published on Dec 10, 2023🔗 View Full Diff —","Book Changelog (part 16)"
47,"1 files updated (7 lines added, 7 lines removed)Minor Updates📅 Published on Dec 10, 2023🔗 View Full Diff — 26 files updated (12807 lines added, 364 lines removed)Major UpdatesAi For Good: +++++ (208 lines added, 1 lines removed)Benchmarking: +++++ (796 lines added, 11 lines removed)Data Engineering: +++++ (436 lines added, 12 lines removed)Dl Primer: +++++ (239 lines added, 1 lines removed)Dsp Spectral Features Block: +++++ (636 lines added, 21 lines removed)Embedded Ml: +++++ (278","Book Changelog (part 17)"
48,"lines added, 5 lines removed)Embedded Sys: +++++ (393 lines added, 2 lines removed)Frameworks: +++++ (708 lines added, 11 lines removed)Hw Acceleration: +++++ (1021 lines added, 12 lines removed)Image Classification: +++++ (563 lines added, 49 lines removed)Kws Nicla: +++++ (395 lines added, 26 lines removed)Motion Classify Ad: +++++ (440 lines added, 32 lines removed)Niclav Sys: +++++ (339 lines added, 30 lines removed)Object Detection Fomo: +++++ (343 lines added, 34 lines removed)On","Book Changelog (part 18)"
49,"device Learning: +++++ (659 lines added, 13 lines removed)Ops: +++++ (827 lines added, 9 lines removed)Optimizations: +++++ (895 lines added, 41 lines removed)Privacy Security: +++++ (1072 lines added, 17 lines removed)Responsible Ai: +++++ (449 lines added, 5 lines removed)Sustainable Ai: +++++ (627 lines added, 10 lines removed)Training: +++++ (932 lines added, 6 lines removed)Minor UpdatesEfficient Ai: +++++ (179 lines added, 5 lines removed)Generative Ai: +++++ (72 lines added, 1 li","Book Changelog (part 19)"
5,"undational research papers by luminaries like Yann LeCun, Geoffrey Hinton, and Yoshua Bengio. In some small part, my hope is that this book will inspire students to chart their own unique paths.I am optimistic about what lies ahead for AI. It has the potential to solve global challenges and unlock creativity in ways we have yet to imagine. To achieve this, however, we must train the next generation of AI engineers and practitioners—those who can transform novel AI algorithms into working syste","Author’s Note (part 4)"
50,"nes removed)Kws Feature Eng: +++++ (153 lines added, 8 lines removed)Robust Ai: ++++++ (50 lines added, 0 lines removed)Workflow: +++++ (97 lines added, 2 lines removed)","Book Changelog (part 20)"
51,"AcknowledgementsThis book, inspired by the TinyML edX course and CS294r at Harvard University, is the result of years of hard work and collaboration with many students, researchers and practitioners. We are deeply indebted to the folks whose groundbreaking work laid its foundation.As our understanding of machine learning systems deepened, we realized that fundamental principles apply across scales, from tiny embedded systems to large-scale deployments.","Acknowledgements (part 1)"
52,"This realization shaped the book’s expansion into an exploration of machine learning systems with the aim of providing a foundation applicable across the spectrum of implementations.Funding Agencies and CompaniesAcademic SupportWe are grateful for the academic support that has made it possible to hire teaching assistants to help improve instructional material and quality:Non-Profit and Institutional SupportWe gratefully acknowledge the support of the following non-profit organizati","Acknowledgements (part 2)"
53,"ons and institutions that have contributed to educational outreach efforts, provided scholarship funds to students in developing countries, and organized workshops to teach using the material:Corporate SupportThe following companies contributed hardware kits used for the labs in this book and/or supported the development of hands-on educational materials:ContributorsWe express our sincere gratitude to the open-source community of learners, educators, and contributors.","Acknowledgements (part 3)"
54,"Each contribution, whether a chapter section or a single-word correction, has significantly enhanced the quality of this resource. We also acknowledge those who have shared insights, identified issues, and provided valuable feedback behind the scenes.A comprehensive list of all GitHub contributors, automatically updated with each new contribution, is available below. For those interested in contributing further, please consult our GitHub page for more information.","Acknowledgements (part 4)"
55,"Vijay Janapa ReddiVijay Janapa ReddijasonjabbourjasonjabbourIkechukwu UchenduIkechukwu UchenduZeljko HrcekZeljko HrcekKai KleinbardKai KleinbardNaeem KhoshnevisNaeem KhoshnevisMarcelo RovaiMarcelo RovaiSara KhosraviSara KhosraviDouwe den BlankenDouwe den BlankenshanzehbatoolshanzehbatoolEliasEliasJared PingJared PingJeffrey MaJeffrey MaItai ShapiraItai ShapiraMaximilian LamMaximilian LamJayson LinJayson LinSophia ChoSophia ChoAndreaAndreaAlex RodriguezAlex","Acknowledgements (part 5)"
56,"” – African ProverbAs a living and breathing resource, this book is a continual work in progress, reflecting the ever-evolving nature of machine learning systems. Advancements in the ML landscape drive our commitment to keeping this resource updated with the latest insights, techniques, and best practices. We warmly invite you to join us on this journey by contributing your expertise, feedback, and ideas.Global OutreachThank you to all our readers and visitors.","preface (part 6)"
57,"RodriguezKorneel Van den BergheKorneel Van den BergheZishen WanZishen WanColby BanburyColby BanburyMark MazumderMark MazumderDivya AmirtharajDivya AmirtharajAbdulrahman MahmoudAbdulrahman MahmoudSrivatsan KrishnanSrivatsan Krishnanmarin-llobetmarin-llobetEmeka EzikeEmeka EzikeAghyad DeebAghyad DeebHaoran QiuHaoran QiuAditi RajuAditi RajuELSuitorHarvardELSuitorHarvardEmil NjorEmil NjorMichael SchneblyMichael SchneblyJared NiJared NioishiboishibYu-Shun HsiaoYu-S","Acknowledgements (part 6)"
58,"hun HsiaoJae-Won ChungJae-Won ChungHenry BaeHenry BaeJennifer ZhouJennifer ZhouArya TschandArya TschandEura NofshinEura NofshinPong TrairatvorakulPong TrairatvorakulMatthew StewartMatthew StewartMarco ZennaroMarco ZennaroAndrew BassAndrew BassShvetank PrakashShvetank PrakashFin AminFin AminAllen-KuangAllen-KuangGauri JainGauri Jaingnodipac886gnodipac886The Random DIYThe Random DIYBruno ScaglioneBruno ScaglioneFatima ShahFatima ShahSercan AygünSercan AygünAlex","Acknowledgements (part 7)"
59,"OesterlingAlex OesterlingBaldassarre CesaranoBaldassarre CesaranoAbenezerAbenezerTheHiddenLayerTheHiddenLayerabigailswallowabigailswallowyanjinglyanjinglhappyappledoghappyappledogYang ZhouYang ZhouAritra GhoshAritra GhoshAndy ChengAndy ChengBilge AcunBilge AcunJessica QuayeJessica QuayeJason YikJason YikEmmanuel RassouEmmanuel RassouShreya JohriShreya JohriSonia MurthySonia MurthyVijay EdupugantiVijay EdupugantiCostin-Andrei OncescuCostin-Andrei OncescuAnnie","Acknowledgements (part 8)"
6,"ms that enable real-world application. This book is a step toward curating the material needed to build the next generation of AI engineers who will transform today’s visions into tomorrow’s reality.This book is a work in progress, but knowing that even one learner benefits from its content motivates me to continually refine and expand it. To that end, if there’s one thing I ask of readers, it’s this: please show your support by starring the GitHub repository here.","Author’s Note (part 5)"
60,"Laurie CookAnnie Laurie CookJothi RamaswamyJothi RamaswamyBatur ArslanBatur ArslanCurren IyerCurren IyerFatima ShahFatima ShahEdward JinEdward Jina-sarafa-sarafsonghansonghanZishenZishen","Acknowledgements (part 9)"
61,"SocratiQ AIAI Learning CompanionWelcome to SocratiQ (pronounced ``Socratic’’), an AI learning assistant seamlessly integrated throughout this resource. Inspired by the Socratic method of teaching—emphasizing thoughtful questions and answers to stimulate critical thinking—SocratiQ is part of our experiment with what we call as Generative Learning. By combining interactive quizzes, personalized assistance, and real-time feedback, SocratiQ is meant to reinforce your understanding and help you cre","SocratiQ AI (part 1)"
62,"ate new connections. SocratiQ is still a work in progress, and we welcome your feedback.Learn more: Read our research paper on SocratiQ’s design and pedagogy here.Listen to this AI-generated podcast about SocratiQ.You can enable SocratiQ by clicking the button below:SocratiQ: OFFDirect URL AccessYou can directly control SocratiQ by adding ?socratiq= parameters to your URL:To activate: mlsysbook.ai/?socratiq=trueTo deactivate: mlsysbook.ai/?","SocratiQ AI (part 2)"
63,"socratiq=falseThis gives you with quick access to toggle SocratiQ’s functionality directly from your browser’s address bar if you are on a page and do not want to return here to toggle functionality.SocratiQ’s goal is to adapt to your needs while generating targeted questions and engaging in meaningful dialogue about the material. Unlike traditional textbook study, SocratiQ offers an interactive, personalized learning experience that can help you better understand and retain complex concepts.","SocratiQ AI (part 3)"
64,"It is only available as an online feature.Quick Start GuideEnable SocratiQ using the button below or URL parametersUse keyboard shortcut (Cmd/Ctrl + /) to open SocratiQ anytimeSet your academic level in SettingsStart learning! Look for quiz buttons at the end of sectionsPlease note that this is an experimental feature. We are experimenting with the idea of creating a dynamic and personalized learning experience by harnessing the power of generative AI.","SocratiQ AI (part 4)"
65,"We hope that this approach will transform how you interact with and absorb the complex concepts.WarningAbout AI Responses: While SocratiQ uses advanced AI to generate quizzes and provide assistance, like all AI systems, it may occasionally provide imperfect or incomplete answers. However, we’ve designed and tested it to ensure it’s effective for supporting your learning journey. If you’re unsure about any response, refer to the textbook content or consult your instructor.","SocratiQ AI (part 5)"
66,"Once you’ve enabled SocratiQ it will always be available when you visit this site.You can access SocratiQ at any time using a keyboard shortcut shown in Figure 1, which brings up the interface shown in Figure 2.Figure 1: Keyboard shortcut for SocratiQ.Figure 2: The main SocratiQ interface, showing the key components of your AI learning assistant.Button OverviewThe top nav bar provides quick access to the following features:Adjust your settings at any time.","SocratiQ AI (part 6)"
67,"Your engagement with the material keeps us motivated.Why We Wrote This BookWhile there are plenty of resources that focus on the algorithmic side of machine learning, resources on the systems side of things are few and far between. This gap inspired us to create this book—a resource dedicated to the principles and practices of building efficient and scalable ML systems.Our vision for this book and its broader mission is deeply rooted in the transformative potential of AI and the need to m","preface (part 7)"
68,"Track your progress by viewing the dashboard.Start new or save your conversations with SocratiQ.Figure 3: View of the top nav menu.Personalize Your LearningBefore diving into your studies, take a moment to configure SocratiQ for your academic level. This initial setup ensures that all interactions, from quiz questions to explanations, are tailored to your background knowledge. Figure 4 shows where you can adjust these preferences.","SocratiQ AI (part 7)"
69,"You can augment any AI SocratiQ response using the dropdown menu at the top of each message.Figure 4: The settings panel where you can customize SocratiQ to match your academic level.Learning with SocratiQQuizzesAs you progress through each section of the textbook, you have the option to ask SocratiQ to automatically generate quizzes tailored to reinforce key concepts. These quizzes are conveniently inserted at the end of every major subsection (e.g., 1.1, 1.2, 1.","SocratiQ AI (part 8)"
7,"Your star ⭐ reflects your belief in this mission—not just to me, but to the growing global community of learners, educators, and practitioners. This small act is more than symbolic—it amplifies the importance of making AI education accessible.I am a student of my own writing, and every chapter of this book has taught me something new—thanks to the numerous people who have played, and continue to play, an important role in shaping this work.","Author’s Note (part 6)"
70,"3, and so on), as illustrated in Figure 6.Figure 5: Redo an AI message by choosing a new experience level.Figure 6: Quizzes are generated at the end of every section.Each quiz typically consists of 3-5 multiple-choice questions and takes only 1-2 minutes to complete. These questions are designed to assess your understanding of the material covered in the preceding section, as shown in Figure 7 (a).","SocratiQ AI (part 9)"
71,"Upon submitting your answers, SocratiQ provides immediate feedback along with detailed explanations for each question, as demonstrated in Figure 7 (b).(a) Example of AI-generated quiz questions. (b) Example of AI-generated feedback and explanations for quizzes.Figure 7: SocratiQ uses a Large Language Model (LLM) to automatically generate and grade quizzes.Example Learning FlowRead a sectionSelect challenging text → Ask SocratiQ for explanationTake the section quizReview related co","SocratiQ AI (part 10)"
72,"ntent suggestionsTrack progress in dashboardGetting Help with ConceptsWhen you encounter challenging concepts, SocratiQ offers two powerful ways to get help. First, you can select any text from the textbook and ask for a detailed explanation, as demonstrated in Figure 8.Figure 8: Selecting specific text to ask for clarification.Once you’ve selected the text, you can ask questions about it, and SocratiQ will provide detailed explanations based on that context, as illustrated in Figure 9.","SocratiQ AI (part 11)"
73,"Figure 9: Example of how SocratiQ provides explanations based on selected text.Figure 11 shows the response for the ask in Figure 9.Additionally, you can also reference Sections, as shown in Figure 10, Sub-sections and keywords directly as you converse with SocratiQ. Use the @ symbol to reference a section, sub-section or keyword. You can also click the + Context button right above the input.Figure 10: Referencing different sections from the textbook.","SocratiQ AI (part 12)"
74,"Figure 11: An interactive chat session with SocratiQ, demonstrating how to get clarification on concepts.To enhance your learning experience, SocratiQ doesn’t just answer your questions—it also suggests related content from the textbook that might be helpful for deeper understanding, as shown in Figure 12.Figure 12: SocratiQ suggests related content based on your questions to help deepen your understanding.","SocratiQ AI (part 13)"
75,"Tracking Your ProgressPerformance DashboardSocratiQ maintains a comprehensive record of your learning journey. The progress dashboard (Figure 13) displays your quiz performance statistics, learning streaks, and achievement badges. This dashboard updates real-time.Figure 13: The progress dashboard showing your learning statistics and achievements.As you continue to engage with the material and complete quizzes, you’ll earn various badges that recognize your progress, as shown in Figure 14.","SocratiQ AI (part 14)"
76,"🏅 Achievement BadgesAs you progress through the quizzes, you’ll earn special badges to mark your achievements! Here’s what you can earn:BadgeNameHow to Earn🎯First StepsComplete your first quiz🔢On a StreakMaintain a streak of perfect scores🏆Quiz MedalistComplete 10 quizzes🏆🏆Quiz ChampionComplete 20 quizzes🏆🏆🏆Quiz LegendComplete 30 quizzes🏆🏆🏆🏆 x nQuiz AGI Super HumanComplete 40 or more quizzesTipKeep taking quizzes to collect all badges and improve your lear","SocratiQ AI (part 15)"
77,"ning journey! Your current badges will appear in the quiz statistics dashboard.Figure 14: Examples of achievement badges you can earn through consistent engagement.If you’d like a record of your progress you can generate a PDF report. It will show your progress, average performance and all the questions you’ve attempted. The PDF is a generated with a unique hash and can be uniquely validated.Figure 15: You can click the Download Report button to view your report.","SocratiQ AI (part 16)"
78,"ake AI education globally accessible to all. To learn more about the inspiration behind this project and the values driving its creation, we encourage you to read the Author’s Note.Want to Help Out?This is a collaborative project, and your input matters! If you’d like to contribute, check out our contribution guidelines. Feedback, corrections, and new ideas are welcome—simply file a GitHub issue.What’s Next?","preface (part 8)"
79,"You can verify that your PDF has been created by SocratiQ by clicking the verify button and uploading your generated PDF.Data StorageImportantImportant Note: All progress data is stored locally in your browser. Clearing your browser history or cache will erase your entire learning history, including quiz scores, streaks, and achievement badges.You can also delete all of your saved conversations by clicking the New Chat button in the nav bar.","SocratiQ AI (part 17)"
8,"Professors, students, practitioners, and researchers contributed by offering suggestions, sharing expertise, identifying errors, and proposing improvements. Every interaction, whether a detailed critique or a simple correction from a GitHub contributor, has been a lesson in itself. These contributions have not only refined the material but also deepened my understanding of how knowledge grows through collaboration.","Author’s Note (part 7)"
80,"Figure 16: Load or delete previous chats or start a new chat.Technical RequirementsTo use SocratiQ effectively, you’ll need:Chrome or Safari browserJavaScript enabledStable internet connectionCommon Issues and TroubleshootingIf SocratiQ isn’t responding: Refresh the pageIf quizzes don’t load: Check your internet connectionIf progress isn’t saving: Ensure cookies are enabledFor persistent issues, please contact us at vj[@]eecs.harvard.edu.","SocratiQ AI (part 18)"
81,"Providing FeedbackYour feedback helps us improve SocratiQ.You can report technical issues, suggest improvements to quiz questions, or share thoughts about AI responses using the feedback buttons located throughout the interface. You can submit a GitHub issue.","SocratiQ AI (part 19)"
82,"If you’re ready to dive deeper into the book’s structure, learning objectives, and practical use, visit the About the Book section for more details.","preface (part 9)"
83,"DALL·E 3 Prompt: A detailed, rectangular, flat 2D illustration depicting a roadmap of a book’s chapters on machine learning systems, set on a crisp, clean white background. The image features a winding road traveling through various symbolic landmarks. Each landmark represents a chapter topic: Introduction, ML Systems, Deep Learning, AI Workflow, Data Engineering, AI Frameworks, AI Training, Efficient AI, Model Optimizations, AI Acceleration, Benchmarking AI, On-Device Learning, Embedded AIOps,","1  Introduction (part 1)"
84,"Security & Privacy, Responsible AI, Sustainable AI, AI for Good, Robust AI, Generative AI. The style is clean, modern, and flat, suitable for a technical book, with each landmark clearly labeled with its chapter title.","1  Introduction (part 2)"
85,"Artificial Intelligence (AI) has emerged as one of the most transformative forces in human history. From the moment we wake up to when we go to sleep, AI systems invisibly shape our world. They manage traffic flows in our cities, optimize power distribution across electrical grids, and enable billions of wireless devices to communicate seamlessly. In hospitals, AI analyzes medical images and helps doctors diagnose diseases.","1.1 AI Pervasiveness (part 1)"
86,"In research laboratories, it accelerates scientific discovery by simulating molecular interactions and processing vast datasets from particle accelerators. In space exploration, it helps rovers navigate distant planets and telescopes detect new celestial phenomena.Throughout history, certain technologies have fundamentally transformed human civilization, defining their eras. The 18th and 19th centuries were shaped by the Industrial Revolution, where steam power and mechanization transformed h","1.1 AI Pervasiveness (part 2)"
87,"ow humans could harness physical energy. The 20th century was defined by the Digital Revolution, where the computer and internet transformed how we process and share information. Now, the 21st century appears to be the era of Artificial Intelligence, a shift noted by leading thinkers in technological evolution (Brynjolfsson and McAfee 2014; Domingos 2016).Brynjolfsson, Erik, and Andrew McAfee. 2014.","1.1 AI Pervasiveness (part 3)"
88,"The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies, 1st Edition. W. W. Norton Company.Domingos, Pedro. 2016. “The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World.” Choice Reviews Online 53 (07): 53–3100. https://doi.org/10.5860/choice.194685.The vision driving AI development extends far beyond the practical applications we see today.","1.1 AI Pervasiveness (part 4)"
89,"We aspire to create systems that can work alongside humanity, enhancing our problem-solving capabilities and accelerating scientific progress. Imagine AI systems that could help us understand consciousness, decode the complexities of biological systems, or unravel the mysteries of dark matter. Consider the potential of AI to help address global challenges like climate change, disease, or sustainable energy production.","1.1 AI Pervasiveness (part 5)"
9,"This book is, therefore, not solely my work; it is a shared endeavor, reflecting the collective spirit of those dedicated to sharing their knowledge and effort.This book is dedicated to the loving memory of my father. His passion for education, endless curiosity, generosity in sharing knowledge, and unwavering commitment to quality challenge me daily to strive for excellence in all I do. In his honor, I extend this dedication to teachers and mentors everywhere, whose efforts and guidance tran","Author’s Note (part 8)"
90,"This is not just about automation or efficiency—it’s about expanding the boundaries of human knowledge and capability.The impact of this revolution operates at multiple scales, each with profound implications. At the individual level, AI personalizes our experiences and augments our daily decision-making capabilities. At the organizational level, it transforms how businesses operate and how research institutions make discoveries.","1.1 AI Pervasiveness (part 6)"
91,"At the societal level, it reshapes everything from transportation systems to healthcare delivery. At the global level, it offers new approaches to addressing humanity’s greatest challenges, from climate change to drug discovery.What makes this transformation unique is its unprecedented pace. While the Industrial Revolution unfolded over centuries and the Digital Revolution over decades, AI capabilities are advancing at an extraordinary rate.","1.1 AI Pervasiveness (part 7)"
92,"Technologies that seemed impossible just years ago—systems that can understand human speech, generate novel ideas, or make complex decisions—are now commonplace. This acceleration suggests we are only beginning to understand how profoundly AI will reshape our world.We stand at a historic inflection point. Just as the Industrial Revolution required us to master mechanical engineering to harness the power of steam and machinery, and the Digital Revolution demanded expertise in electrical and co","1.1 AI Pervasiveness (part 8)"
93,"mputer engineering to build the internet age, the AI Revolution presents us with a new engineering challenge. We must learn to build systems that can learn, reason, and potentially achieve superhuman capabilities in specific domains.","1.1 AI Pervasiveness (part 9)"
94,"The exploration of artificial intelligence’s transformative impact across society presents a fundamental question: How can we create these intelligent capabilities? Understanding the relationship between AI and ML provides the theoretical and practical framework necessary to address this question.Artificial Intelligence represents the systematic pursuit of understanding and replicating intelligent behavior—specifically, the capacity to learn, reason, and adapt to new situations.","1.2 AI and ML Basics (part 1)"
95,"It encompasses fundamental questions about the nature of intelligence, knowledge, and learning. How do we recognize patterns? How do we learn from experience? How do we adapt our behavior based on new information? AI as a field explores these questions, drawing insights from cognitive science, psychology, neuroscience, and computer science.Machine Learning, in contrast, constitutes the methodological approach to creating systems that demonstrate intelligent behavior.","1.2 AI and ML Basics (part 2)"
96,"Instead of implementing intelligence through predetermined rules, machine learning systems utilize gradient descent and other optimization techniques to identify patterns and relationships. This methodology reflects fundamental learning processes observed in biological systems. For instance, object recognition in machine learning systems parallels human visual learning processes, requiring exposure to numerous examples to develop robust recognition capabilities.","1.2 AI and ML Basics (part 3)"
97,"Similarly, natural language processing systems acquire linguistic capabilities through extensive analysis of textual data.AI and ML: Key DefinitionsArtificial Intelligence (AI): The goal of creating machines that can match or exceed human intelligence—representing humanity’s quest to build systems that can think, reason, and adapt.Machine Learning (ML): The scientific discipline of understanding how systems can learn and improve from experience—providing the theoretical foundation for buil","1.2 AI and ML Basics (part 4)"
98,"ding intelligent systems.The relationship between AI and ML exemplifies the connection between theoretical understanding and practical engineering implementation observed in other scientific fields. For instance, physics provides the theoretical foundation for mechanical engineering’s practical applications in structural design and machinery, while AI’s theoretical frameworks inform machine learning’s practical development of intelligent systems.","1.2 AI and ML Basics (part 5)"
99,"Similarly, electrical engineering’s transformation of electromagnetic theory into functional power systems parallels machine learning’s implementation of intelligence theories into operational ML systems.The emergence of machine learning as a viable scientific discipline approach to artificial intelligence resulted from extensive research and fundamental paradigm shifts in the field. The progression of artificial intelligence encompasses both theoretical advances in understanding intelligence","1.2 AI and ML Basics (part 6)"
